{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strided_window(a, window_size, step_size):\n",
    "    #https://stackoverflow.com/questions/40084931/taking-subarrays-from-numpy-array-with-given-stride-stepsize/40085052#40085052\n",
    "    nrows = ((a.size-window_size)//step_size)+1\n",
    "    n     = a.strides[0]\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=(nrows,window_size), strides=(step_size*n,n), writeable=False)\n",
    "\n",
    "def generate_view(ohlcv_data, lookback):\n",
    "    \"\"\"\n",
    "    Generates numpy view of ohlcv_data with shape (nrows-lookback, ncols*lookback)\n",
    "    :ohlcv_data: a contiguous numpy array with shape (n,m)\n",
    "    :lookback: an integer specifying how many periods to include in each row\n",
    "    \"\"\"\n",
    "    ncols  = ohlcv_data.shape[1]\n",
    "    prices = ohlcv_data.ravel()\n",
    "    #get views (references) of prices (no copying, no extra memory)\n",
    "    prices_strided = strided_window(prices, window_size=lookback*ncols, step_size = ncols)\n",
    "    return prices_strided[:-1]\n",
    "\n",
    "\n",
    "def get_raw_data(year):\n",
    "    df = pd.read_csv('./Polygon/Raw/SPY_{}.csv'.format(year), engine='c', index_col=['t'], usecols = ['t','p','s'], dtype={'t':np.int64, 'p':np.float64, 's':np.float64})\n",
    "    #convert index to pd.DatetimeIndex, timezone naive, daylight savings naive\n",
    "    df.index = pd.to_datetime(df.index, unit='ns')\n",
    "    #convert index to US-Eastern timezone, automatically takes care of daylight savings\n",
    "    df.index = df.index.tz_localize('UTC').tz_convert('US/Eastern')\n",
    "    #restrict data to trading hours\n",
    "    df = df.between_time('09:30:00', '16:00:00')\n",
    "    return df\n",
    "\n",
    "def calc_ohlcv(df, period):\n",
    "    #period = microseconds(U) | milliseconds(L) | seconds(S) | minutes(T) | hour(H)\n",
    "    temp = df.resample(period).agg({'p': 'ohlc', 's': 'sum'})\n",
    "    temp.columns = ['open','high','low','close','volume']\n",
    "    temp['close'].fillna(method='ffill', inplace=True)\n",
    "    temp['open'].fillna(temp['close'], inplace=True)\n",
    "    temp['high'].fillna(temp['close'], inplace=True)\n",
    "    temp['low'].fillna(temp['close'], inplace=True)\n",
    "    return temp\n",
    "\n",
    "def ohlcv_generator(year, resample_freq = 'T', measure = 'high', lookback_memory = 1):\n",
    "    spy = get_raw_data(year)\n",
    "    for month_name, month_group in spy.groupby(pd.Grouper(freq='M')):\n",
    "        for day_name, day_group in month_group.groupby(pd.Grouper(freq='D')):\n",
    "            #get ohlcv data\n",
    "            ohlcv_temp = calc_ohlcv(day_group, resample_freq)\n",
    "            #take measure as outcome\n",
    "            Ytrain = ohlcv_temp[measure].values[lookback_memory:]\n",
    "            #generate training data\n",
    "            Xtrain = generate_view(ohlcv_temp.values, lookback_memory)\n",
    "            for i in range(Xtrain.shape[0]):\n",
    "                yield Xtrain[i], Ytrain[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((5,), ()), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator = tf.data.Dataset.from_generator(\n",
    "                    generator     = ohlcv_generator, args=[2003], \n",
    "                    output_types  = (tf.float32, tf.float32),\n",
    "                    output_shapes =(tf.TensorShape([5]), tf.TensorShape([]))) \n",
    "     \n",
    "test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: id=509, shape=(5, 5), dtype=float32, numpy=\n",
      "array([[1.06850e+02, 1.06930e+02, 1.06840e+02, 1.06930e+02, 5.36500e+05],\n",
      "       [1.06910e+02, 1.06950e+02, 1.06750e+02, 1.06920e+02, 1.14700e+05],\n",
      "       [1.06930e+02, 1.06950e+02, 1.06890e+02, 1.06940e+02, 1.71600e+05],\n",
      "       [1.06920e+02, 1.07010e+02, 1.06901e+02, 1.06990e+02, 1.56100e+05],\n",
      "       [1.07000e+02, 1.07020e+02, 1.06910e+02, 1.06990e+02, 3.43300e+05]],\n",
      "      dtype=float32)>, <tf.Tensor: id=510, shape=(5,), dtype=float32, numpy=array([106.95, 106.95, 107.01, 107.02, 107.03], dtype=float32)>)\n",
      "(<tf.Tensor: id=511, shape=(5, 5), dtype=float32, numpy=\n",
      "array([[1.0702e+02, 1.0703e+02, 1.0691e+02, 1.0702e+02, 2.9690e+05],\n",
      "       [1.0702e+02, 1.0709e+02, 1.0695e+02, 1.0696e+02, 8.9600e+04],\n",
      "       [1.0696e+02, 1.0701e+02, 1.0695e+02, 1.0696e+02, 2.5050e+05],\n",
      "       [1.0696e+02, 1.0705e+02, 1.0690e+02, 1.0692e+02, 9.4700e+04],\n",
      "       [1.0692e+02, 1.0697e+02, 1.0688e+02, 1.0689e+02, 9.2700e+04]],\n",
      "      dtype=float32)>, <tf.Tensor: id=512, shape=(5,), dtype=float32, numpy=array([107.09, 107.01, 107.05, 106.97, 106.94], dtype=float32)>)\n",
      "(<tf.Tensor: id=513, shape=(5, 5), dtype=float32, numpy=\n",
      "array([[1.06900e+02, 1.06940e+02, 1.06860e+02, 1.06931e+02, 4.22000e+04],\n",
      "       [1.06880e+02, 1.06930e+02, 1.06830e+02, 1.06850e+02, 6.65000e+04],\n",
      "       [1.06870e+02, 1.06890e+02, 1.06830e+02, 1.06840e+02, 1.77500e+05],\n",
      "       [1.06880e+02, 1.06880e+02, 1.06830e+02, 1.06850e+02, 2.41100e+05],\n",
      "       [1.06850e+02, 1.06900e+02, 1.06850e+02, 1.06880e+02, 1.10200e+05]],\n",
      "      dtype=float32)>, <tf.Tensor: id=514, shape=(5,), dtype=float32, numpy=array([106.93, 106.89, 106.88, 106.9 , 106.94], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "for trade_batch in test_generator.repeat().batch(5).take(3):\n",
    "    print(trade_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 16\n",
    "# using two numpy arrays\n",
    "features, labels = (np.array([np.random.sample((100,2))]), \n",
    "                    np.array([np.random.sample((100,1))]))\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "                    generator     = ohlcv_generator, args=[2003], \n",
    "                    output_types  = (tf.float32, tf.float32),\n",
    "                    output_shapes =(tf.TensorShape([5]), tf.TensorShape([]))).repeat().batch(BATCH_SIZE)\n",
    "iter = dataset.make_one_shot_iterator()\n",
    "x, y = iter.get_next()\n",
    "# make a simple model\n",
    "net = tf.layers.dense(x, 8, activation=tf.tanh) # pass the first value from iter.get_next() as input\n",
    "net = tf.layers.dense(net, 8, activation=tf.tanh)\n",
    "prediction = tf.layers.dense(net, 1, activation=tf.tanh)\n",
    "loss = tf.losses.mean_squared_error(prediction, y) # pass the second value from iter.get_net() as label\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(EPOCHS):\n",
    "        _, loss_value = sess.run([train_op, loss])\n",
    "        print(\"Iter: {}, Loss: {:.4f}\".format(i, loss_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import multiprocessing as mp\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import gc\n",
    "\n",
    "pd.plotting.register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Get trade data from polygon.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.a Define api key, url endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = json.load(open('Polygon/api-key.json'))['API-KEY']\n",
    "url     = 'https://api.polygon.io/v2/ticks/stocks/trades/{symbol}/{date}?timestamp={timestamp}&limit={limit}&apiKey={api_key}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b Define function to get trades for a single date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trades(date):\n",
    "    \"\"\"\n",
    "    Get all trades that occurred on a given date\n",
    "    \"\"\"\n",
    "    params = {\n",
    "    'symbol': 'SPY',\n",
    "    'date': date,\n",
    "    'timestamp': '0',\n",
    "    'limit': 50000,\n",
    "    'api_key': api_key\n",
    "    }\n",
    "    trade_data    = []\n",
    "    results_count = params['limit']\n",
    "    \n",
    "    #API limits response to 50k trades per request\n",
    "    #this loop keeps requesting until it has exhausted all trades\n",
    "    while results_count >= params['limit']:\n",
    "        response = requests.get(url.format(**params)).json()\n",
    "        if 'results' in response:\n",
    "            results_count       = response['results_count']\n",
    "            trade_data         += response['results']\n",
    "            #replace starting timestamp of request with last trade's timestamp\n",
    "            params['timestamp'] = response['results'][-1]['t']\n",
    "        else:\n",
    "            results_count = 0\n",
    "            \n",
    "    return trade_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.c Get trades for every day between January 1st 2003 and December 31st 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2004, 2020):\n",
    "    #generate all dates in the year in format 2020-03-12 (year-month-day)\n",
    "    dates = [str(x)[:10] for x in pd.date_range('{}-01-01'.format(year), '{}-12-31'.format(year), freq='D')]\n",
    "    \n",
    "    #8 cores, so use multiprocess requests to Polygon.io\n",
    "    with mp.Pool(8) as pool:\n",
    "        #creates a list of dictionaries, each dictionary will become a row in the dataframe\n",
    "        trade_data = list(itertools.chain.from_iterable(pool.map(get_trades, dates)))\n",
    "    \n",
    "    #combine data into a pandas dataframe\n",
    "    spydf = pd.DataFrame(trade_data)\n",
    "        \n",
    "    #write to CSV file\n",
    "    spydf.to_csv('Polygon/Raw/SPY_{}.csv'.format(year), index = False)\n",
    "    \n",
    "    #deallocate and free up memory\n",
    "    del trade_data\n",
    "    del spydf\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Trim data and export as binary file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.a Define function for trimming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prime(year):\n",
    "    \"\"\"\n",
    "    Read in SPY_{year}.csv\n",
    "    - create datetime index\n",
    "    - convert to US/Eastern timezone\n",
    "    - trim to trading hours\n",
    "    - remove outliers\n",
    "    \"\"\"\n",
    "    #read in the CSV file of trades\n",
    "    df = pd.read_csv('Polygon/Raw/SPY_{}.csv'.format(year), engine='c', index_col=['t'], usecols = ['t','p','s'], dtype={'t':np.int64, 'p':np.float32, 's':np.float32})\n",
    "    \n",
    "    #order columns\n",
    "    df = df.loc[:,['p','s']]\n",
    "    \n",
    "    #convert index to pd.DatetimeIndex, timezone naive, daylight savings naive\n",
    "    df.index = pd.to_datetime(df.index, unit='ns')\n",
    "    \n",
    "    #convert index to US-Eastern timezone, automatically takes care of daylight savings\n",
    "    df.index = df.index.tz_localize('UTC').tz_convert('US/Eastern')\n",
    "    \n",
    "    #restrict data to trading hours\n",
    "    df = df.between_time('09:30:00', '16:00:00')\n",
    "    \n",
    "    #remove trades with zero shares\n",
    "    df = df[df['s'] > 0]\n",
    "    \n",
    "    #remove outliers = pct change >= 1%\n",
    "    df = df.groupby(pd.Grouper(freq='D'), as_index=False).apply(lambda g: g[abs(((g['p'].shift(-1)-g['p']) / g['p']) < 0.01)]).reset_index(level=0, drop=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.b Define function for exporting binary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_binary(df):\n",
    "    \"\"\"\n",
    "    Take a SPY dataframe and export it as a binary file to be read in later\n",
    "    np.fromfile takes 300 milliseconds\n",
    "    pd.read_csv takes 5 seconds\n",
    "    \"\"\"\n",
    "    #convert datetime index to integer index with 64 bits (8 bytes)\n",
    "    df.index = df.index.astype(np.int64)\n",
    "    \n",
    "    #reset index to make it a column (thus placing it in df.values)\n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "    #make sure that the data type of the numpy array is float with 64 bits (8 bytes)\n",
    "    #np.fromfile will corrupt if this is false\n",
    "    assert df.values.dtype == np.float64\n",
    "    \n",
    "    #export numpy array as binary file\n",
    "    #NOT PLATFORM INDEPENDENT\n",
    "    df.values.tofile('Polygon/Primed/SPY_{}.binary'.format(year))\n",
    "    \n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.c Trim data and export in binary format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2003, 2021):\n",
    "    print(year)\n",
    "    \n",
    "    #clean and trim data\n",
    "    df = prime(year)\n",
    "    \n",
    "    #export as binary file\n",
    "    to_binary(df)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
